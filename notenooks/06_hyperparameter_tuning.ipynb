{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "w3s5qXu9SDCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n"
      ],
      "metadata": {
        "id": "A3q_OvHISE6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"heart_disease_reduced.csv\")\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "X = df.drop(columns=[\"target\"])\n",
        "y = df[\"target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "\n",
        "\n",
        "# Cell 3: GridSearchCV for Random Forest with Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "rf_params = {\n",
        "    \"rf__n_estimators\": [50, 100, 200],\n",
        "    \"rf__max_depth\": [None, 5, 10],\n",
        "    \"rf__min_samples_split\": [2, 5, 10],\n",
        "}\n",
        "\n",
        "rf_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),  # included for consistency\n",
        "    (\"rf\", RandomForestClassifier(random_state=42, class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "grid_rf = GridSearchCV(rf_pipeline, rf_params, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best RF Params:\", grid_rf.best_params_)\n",
        "print(\"Best RF AUC (CV):\", grid_rf.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "rf_best = grid_rf.best_estimator_\n",
        "y_pred_rf = rf_best.predict(X_test)\n",
        "y_proba_rf = rf_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nRandom Forest Test Results:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_proba_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp-jyqkPjVy5",
        "outputId": "8205bb3e-b43c-4d3f-854a-0e23c6ad36c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (303, 9)\n",
            "Train shape: (242, 8) Test shape: (61, 8)\n",
            "Best RF Params: {'rf__max_depth': 5, 'rf__min_samples_split': 10, 'rf__n_estimators': 50}\n",
            "Best RF AUC (CV): 0.8786893460806503\n",
            "\n",
            "Random Forest Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.83        33\n",
            "           1       0.76      0.93      0.84        28\n",
            "\n",
            "    accuracy                           0.84        61\n",
            "   macro avg       0.85      0.84      0.84        61\n",
            "weighted avg       0.85      0.84      0.84        61\n",
            "\n",
            "Test ROC AUC: 0.9204545454545454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: RandomizedSearchCV for SVM with Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "svm_params = {\n",
        "    \"svc__C\": [0.1, 1, 10, 100],\n",
        "    \"svc__gamma\": [0.001, 0.01, 0.1, 1],\n",
        "    \"svc__kernel\": [\"rbf\", \"poly\", \"sigmoid\"]\n",
        "}\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"svc\", SVC(probability=True, random_state=42, class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "rand_svm = RandomizedSearchCV(\n",
        "    svm_pipeline, svm_params, n_iter=30, cv=5, scoring=\"roc_auc\", random_state=42, n_jobs=-1\n",
        ")\n",
        "rand_svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best SVM Params:\", rand_svm.best_params_)\n",
        "print(\"Best SVM AUC (CV):\", rand_svm.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "svm_best = rand_svm.best_estimator_\n",
        "y_pred_svm = svm_best.predict(X_test)\n",
        "y_proba_svm = svm_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nSVM Test Results:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_proba_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mWVe18fjkb4",
        "outputId": "577e2335-bf9f-456e-c4a5-f17236660b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Params: {'svc__kernel': 'sigmoid', 'svc__gamma': 0.01, 'svc__C': 10}\n",
            "Best SVM AUC (CV): 0.8949945384727993\n",
            "\n",
            "SVM Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.82      0.87        33\n",
            "           1       0.81      0.93      0.87        28\n",
            "\n",
            "    accuracy                           0.87        61\n",
            "   macro avg       0.87      0.87      0.87        61\n",
            "weighted avg       0.88      0.87      0.87        61\n",
            "\n",
            "Test ROC AUC: 0.9247835497835498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: GridSearchCV for Logistic Regression\n",
        "lr_params = {\n",
        "    \"logreg__C\": [0.01, 0.1, 1, 10],\n",
        "    \"logreg__penalty\": [\"l1\", \"l2\"]\n",
        "}\n",
        "\n",
        "lr_pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logreg\", LogisticRegression(max_iter=1000, solver=\"liblinear\", class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "grid_lr = GridSearchCV(lr_pipe, lr_params, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Logistic Regression Params:\", grid_lr.best_params_)\n",
        "print(\"Best Logistic Regression AUC (CV):\", grid_lr.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "lr_best = grid_lr.best_estimator_\n",
        "y_pred_lr = lr_best.predict(X_test)\n",
        "y_proba_lr = lr_best.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\nLogistic Regression Test Results:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_proba_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7U1yLOXklPR",
        "outputId": "f1ef1971-ca43-47b2-93fe-e2910db5cb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression Params: {'logreg__C': 10, 'logreg__penalty': 'l1'}\n",
            "Best Logistic Regression AUC (CV): 0.8915306915306915\n",
            "\n",
            "Logistic Regression Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83        33\n",
            "           1       0.79      0.82      0.81        28\n",
            "\n",
            "    accuracy                           0.82        61\n",
            "   macro avg       0.82      0.82      0.82        61\n",
            "weighted avg       0.82      0.82      0.82        61\n",
            "\n",
            "Test ROC AUC: 0.9199134199134199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: GridSearchCV for Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "dt_params = {\n",
        "    \"dt__max_depth\": [None, 3, 5, 10],\n",
        "    \"dt__min_samples_split\": [2, 5, 10],\n",
        "    \"dt__criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "dt_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),  # scaler included for consistency\n",
        "    (\"dt\", DecisionTreeClassifier(random_state=42, class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "grid_dt = GridSearchCV(dt_pipeline, dt_params, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best DT Params:\", grid_dt.best_params_)\n",
        "print(\"Best DT AUC (CV):\", grid_dt.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "dt_best = grid_dt.best_estimator_\n",
        "y_pred_dt = dt_best.predict(X_test)\n",
        "y_proba_dt = dt_best.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\nDecision Tree Test Results:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_proba_dt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eiydvc6SlNaz",
        "outputId": "ed874d99-c8dc-42cd-9016-bc64ac71e156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best DT Params: {'dt__criterion': 'gini', 'dt__max_depth': 3, 'dt__min_samples_split': 2}\n",
            "Best DT AUC (CV): 0.8418645766471855\n",
            "\n",
            "Decision Tree Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82        33\n",
            "           1       0.81      0.75      0.78        28\n",
            "\n",
            "    accuracy                           0.80        61\n",
            "   macro avg       0.80      0.80      0.80        61\n",
            "weighted avg       0.80      0.80      0.80        61\n",
            "\n",
            "Test ROC AUC: 0.8652597402597402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Compare Baseline vs Optimized Models\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# Collect baseline results (from supervised part 2.4 using baseline_preds dict)\n",
        "baseline_results = {\n",
        "    \"Random Forest (base)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, baseline_preds[\"rf\"][0]),\n",
        "        \"f1\": f1_score(y_test, baseline_preds[\"rf\"][0]),\n",
        "        \"roc_auc\": roc_auc_score(y_test, baseline_preds[\"rf\"][1])\n",
        "    },\n",
        "    \"SVM (base)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, baseline_preds[\"svm\"][0]),\n",
        "        \"f1\": f1_score(y_test, baseline_preds[\"svm\"][0]),\n",
        "        \"roc_auc\": roc_auc_score(y_test, baseline_preds[\"svm\"][1])\n",
        "    },\n",
        "    \"LogReg (base)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, baseline_preds[\"lr\"][0]),\n",
        "        \"f1\": f1_score(y_test, baseline_preds[\"lr\"][0]),\n",
        "        \"roc_auc\": roc_auc_score(y_test, baseline_preds[\"lr\"][1])\n",
        "    },\n",
        "    \"Decision Tree (base)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, baseline_preds[\"dt\"][0]),\n",
        "        \"f1\": f1_score(y_test, baseline_preds[\"dt\"][0]),\n",
        "        \"roc_auc\": roc_auc_score(y_test, baseline_preds[\"dt\"][1])\n",
        "    }\n",
        "}\n",
        "\n",
        "#  Collect optimized results (from hyperparameter tuning)\n",
        "optimized_results = {\n",
        "    \"Random Forest (opt)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, rf_best.predict(X_test)),\n",
        "        \"f1\": f1_score(y_test, rf_best.predict(X_test)),\n",
        "        \"roc_auc\": roc_auc_score(y_test, rf_best.predict_proba(X_test)[:,1])\n",
        "    },\n",
        "    \"SVM (opt)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, svm_best.predict(X_test)),\n",
        "        \"f1\": f1_score(y_test, svm_best.predict(X_test)),\n",
        "        \"roc_auc\": roc_auc_score(y_test, svm_best.predict_proba(X_test)[:,1])\n",
        "    },\n",
        "    \"LogReg (opt)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, lr_best.predict(X_test)),\n",
        "        \"f1\": f1_score(y_test, lr_best.predict(X_test)),\n",
        "        \"roc_auc\": roc_auc_score(y_test, lr_best.predict_proba(X_test)[:,1])\n",
        "    },\n",
        "    \"Decision Tree (opt)\": {\n",
        "        \"accuracy\": accuracy_score(y_test, dt_best.predict(X_test)),\n",
        "        \"f1\": f1_score(y_test, dt_best.predict(X_test)),\n",
        "        \"roc_auc\": roc_auc_score(y_test, dt_best.predict_proba(X_test)[:,1])\n",
        "    }\n",
        "}\n",
        "\n",
        "#  Merge into one table and round\n",
        "all_results = {**baseline_results, **optimized_results}\n",
        "results_df = pd.DataFrame(all_results).T.round(3)\n",
        "\n",
        "#  Compute a balanced score = mean of Accuracy, F1, ROC AUC\n",
        "results_df[\"balanced_score\"] = results_df[[\"accuracy\", \"f1\", \"roc_auc\"]].mean(axis=1)\n",
        "\n",
        "print(\"\\n=== Model Comparison ===\")\n",
        "print(results_df)\n",
        "\n",
        "#  Identify best model by balanced score\n",
        "best_model = results_df[\"balanced_score\"].idxmax()\n",
        "print(\"\\nBest Model (Balanced Score):\", best_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-Ksn4KYlYUQ",
        "outputId": "fe278789-28ac-4458-81dc-9459bbb636cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Comparison ===\n",
            "                      accuracy     f1  roc_auc  balanced_score\n",
            "Random Forest (base)     0.803  0.800    0.901        0.834667\n",
            "SVM (base)               0.820  0.820    0.929        0.856333\n",
            "LogReg (base)            0.820  0.807    0.919        0.848667\n",
            "Decision Tree (base)     0.770  0.774    0.840        0.794667\n",
            "Random Forest (opt)      0.836  0.839    0.920        0.865000\n",
            "SVM (opt)                0.869  0.867    0.925        0.887000\n",
            "LogReg (opt)             0.820  0.807    0.920        0.849000\n",
            "Decision Tree (opt)      0.803  0.778    0.865        0.815333\n",
            "\n",
            "Best Model (Balanced Score): SVM (opt)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The base SVM achieved the highest ROC AUC (0.929), indicating slightly stronger class separation. However, the optimized SVM achieved higher accuracy (0.869) and F1-score (0.862), making it more effective at practical classification. Therefore, we selected the optimized SVM as the final model for deployment."
      ],
      "metadata": {
        "id": "mqpTOdKd9XSd"
      }
    }
  ]
}